{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPIhnniiu8FGYpaF63Sw8ep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThiruvarankanM/Self-Supervised-Card-Classification/blob/main/Card_Classification_SelfSupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Imports\n",
        "This section installs necessary libraries and imports the modules needed for the project."
      ],
      "metadata": {
        "id": "hezdtj5ebqf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp_Z-NsHAhFH",
        "outputId": "55eb32d0-d154-4617-d179-00f7e56d6a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gdown if not already installed\n",
        "!pip install -U gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dfz2QJDEGe5",
        "outputId": "cb4e1f41-5908-4b67-fcd0-aec106cbcaa5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "This code mounts your Google Drive to access files stored there."
      ],
      "metadata": {
        "id": "2TMRshobb2XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive and download required folders using gdown\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmdKSYc5EKQB",
        "outputId": "8b4ddbd9-3767-4dd1-a4fb-034889cb4edb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries\n",
        "\n",
        "Importing the necessary libraries for working with PyTorch, images, and file operations."
      ],
      "metadata": {
        "id": "MP44-qtob801"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # PyTorch core library\n",
        "import torch.nn as nn  # Neural network layers\n",
        "import torch.optim as optim  # Optimization algorithms\n",
        "from torch.utils.data import Dataset, DataLoader  # Dataset and data loading utilities\n",
        "from torchvision import transforms  # Image transformations\n",
        "from PIL import Image  # Image processing\n",
        "import os  # File and directory operations\n",
        "import random  # Random number generation"
      ],
      "metadata": {
        "id": "AERbVoHpEuXy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Card Rotation Dataset Class\n",
        "\n",
        "This class defines a custom dataset for the self-supervised learning phase. It loads images from a directory, applies random rotations (0, 90, 180, 270 degrees), and assigns a corresponding label."
      ],
      "metadata": {
        "id": "MYU-n7smcCVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CardRotationDataset(Dataset):\n",
        "    def __init__(self, root_dir, image_size=(128, 128)):\n",
        "        if not os.path.isdir(root_dir):\n",
        "            raise FileNotFoundError(f\"The folder '{root_dir}' does not exist. Please check the path.\")\n",
        "        self.root_dir = root_dir\n",
        "        self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir)\n",
        "                            if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        if len(self.image_paths) == 0:\n",
        "            raise RuntimeError(f\"No image files found in '{root_dir}'. Please ensure the folder contains images.\")\n",
        "        # Transform: resize and convert images to tensor\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.image_size = image_size\n",
        "        self.num_channels = 3\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        # Randomly rotate image and assign label based on rotation\n",
        "        rotation_angle = random.choice([0, 90, 180, 270])\n",
        "        if rotation_angle == 0:\n",
        "            label = 0\n",
        "        elif rotation_angle == 90:\n",
        "            image = image.rotate(90)\n",
        "            label = 1\n",
        "        elif rotation_angle == 180:\n",
        "            image = image.rotate(180)\n",
        "            label = 2\n",
        "        else:\n",
        "            image = image.rotate(270)\n",
        "            label = 3\n",
        "        image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "8ZKvdc_OExCV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple CNN Model\n",
        "\n",
        "This defines a simple Convolutional Neural Network (CNN) model. It consists of an encoder part to extract features and a classifier head."
      ],
      "metadata": {
        "id": "5vLFeHQicHnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, image_size=(128, 128)):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Calculate the size of the flattened output to correctly define the Linear layer\n",
        "        # This calculation assumes the input image is 128x128\n",
        "        # (128 / 2 / 2) * (128 / 2 / 2) * 32_channels = 32 * 32 * 32\n",
        "        flattened_size = (image_size[0] // 4) * (image_size[1] // 4) * 32\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(flattened_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 4) # 4 classes: 0, 90, 180, 270 degrees\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        output = self.classifier(features)\n",
        "        return output"
      ],
      "metadata": {
        "id": "Ro_UTqyjE3Qh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Self-Supervised Model Function\n",
        "\n",
        "This function trains the CNN model using the self-supervised rotation task. It loads the dataset, defines the model, loss function, and optimizer, and then trains the model for a specified number of epochs. The encoder part of the model is saved after training."
      ],
      "metadata": {
        "id": "oFtL7NS0E-pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_self_supervised_model():\n",
        "    data_folder = '/content/drive/MyDrive/my_card_images'  # Use Google Drive path\n",
        "    target_image_size = (128, 128)\n",
        "    try:\n",
        "        dataset = CardRotationDataset(root_dir=data_folder, image_size=target_image_size)\n",
        "        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "    except (FileNotFoundError, RuntimeError) as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return\n",
        "    model = SimpleCNN(image_size=target_image_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    print(f\"\\n--- Starting Self-Supervised Training on images in '{data_folder}' ---\")\n",
        "    for epoch in range(10):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader):.4f}\")\n",
        "    torch.save(model.encoder.state_dict(), 'self_supervised_encoder.pth')\n",
        "    print(\"\\nTraining finished! Saved the encoder to 'self_supervised_encoder.pth'.\")"
      ],
      "metadata": {
        "id": "d_rW_nQfE8_d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Self-Supervised Training\n",
        "\n",
        "This block calls the `train_self_supervised_model` function to start the self-supervised training process when the script is executed."
      ],
      "metadata": {
        "id": "WQcWeJhDcSuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import glob\n",
        "\n",
        "Importing the `glob` library for finding files matching a pattern."
      ],
      "metadata": {
        "id": "4ynaqHH6cXrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the self-supervised training if this script is executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    train_self_supervised_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef9-Uxk4FApR",
        "outputId": "ee1ac794-e175-4228-b33d-033b71270bf1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Self-Supervised Training on images in '/content/drive/MyDrive/my_card_images' ---\n",
            "Epoch 1, Loss: 0.6587\n",
            "Epoch 2, Loss: 0.0846\n",
            "Epoch 3, Loss: 0.0060\n",
            "Epoch 4, Loss: 0.0006\n",
            "Epoch 5, Loss: 0.0001\n",
            "Epoch 6, Loss: 0.0000\n",
            "Epoch 7, Loss: 0.0000\n",
            "Epoch 8, Loss: 0.0000\n",
            "Epoch 9, Loss: 0.0000\n",
            "Epoch 10, Loss: 0.0000\n",
            "\n",
            "Training finished! Saved the encoder to 'self_supervised_encoder.pth'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Labeled Card Dataset Class\n",
        "\n",
        "This class defines a dataset for the supervised fine-tuning phase. It loads images from a directory organized into subfolders (each subfolder representing a class) and assigns class labels."
      ],
      "metadata": {
        "id": "nRwZfOmdcc09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob  # For file path pattern matching"
      ],
      "metadata": {
        "id": "NeyPMv89FCdr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabeledCardDataset(Dataset):\n",
        "    def __init__(self, root_dir, image_size=(128, 128)):\n",
        "        self.root_dir = root_dir\n",
        "        # Get class names from subfolder names\n",
        "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        # Collect image paths and their class labels\n",
        "        self.image_paths = []\n",
        "        for cls_name in self.classes:\n",
        "            cls_path = os.path.join(root_dir, cls_name)\n",
        "            for img_name in glob.glob(os.path.join(cls_path, '*')):\n",
        "                self.image_paths.append((img_name, self.class_to_idx[cls_name]))\n",
        "        if len(self.image_paths) == 0:\n",
        "            raise RuntimeError(f\"No labeled images found in '{root_dir}'.\")\n",
        "        # Transform: resize and convert images to tensor\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "qzNFKCw3FIud"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Classifier Model\n",
        "\n",
        "This class defines the full classifier model used for fine-tuning and prediction. It loads the pre-trained encoder from the self-supervised phase and adds a new classifier head for the card classification task. The encoder weights are frozen during fine-tuning."
      ],
      "metadata": {
        "id": "Kix65Etfckrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullClassifier(nn.Module):\n",
        "    def __init__(self, encoder_path, num_classes):\n",
        "        super(FullClassifier, self).__init__()\n",
        "        # Define encoder structure (must match pre-trained encoder)\n",
        "        class SimpleCNN_Encoder(nn.Module):\n",
        "            def __init__(self):\n",
        "                super(SimpleCNN_Encoder, self).__init__()\n",
        "                self.encoder = nn.Sequential(\n",
        "                    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2, 2),\n",
        "                    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2, 2)\n",
        "                )\n",
        "            def forward(self, x):\n",
        "                return self.encoder(x)\n",
        "        # Load pre-trained encoder weights\n",
        "        self.encoder = SimpleCNN_Encoder().encoder\n",
        "        self.encoder.load_state_dict(torch.load(encoder_path))\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False  # Freeze encoder weights\n",
        "        # Add classifier head for fine-tuning\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 32 * 32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        output = self.classifier(features)\n",
        "        return output"
      ],
      "metadata": {
        "id": "796QUZN7FKTh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finetune Supervised Model Function\n",
        "\n",
        "This function performs supervised fine-tuning on the labeled card dataset. It loads the labeled dataset, the pre-trained encoder, adds a classifier head, and trains only the classifier head for a few epochs."
      ],
      "metadata": {
        "id": "RF0tXypPcsci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune_supervised_model():\n",
        "    data_folder = '/content/drive/MyDrive/cards_labeled_small'  # Path for Colab uploads\n",
        "    try:\n",
        "        dataset = LabeledCardDataset(root_dir=data_folder)\n",
        "        dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return\n",
        "    num_classes = len(dataset.classes)\n",
        "    model = FullClassifier(encoder_path='self_supervised_encoder.pth', num_classes=num_classes)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)  # Only update classifier\n",
        "    print(f\"\\n--- Starting Supervised Finetuning on {len(dataset)} labeled images ---\")\n",
        "    for epoch in range(20):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader):.4f}\")\n",
        "    print(\"\\nFinetuning finished! The model is now ready for card classification.\")\n",
        "    print(f\"Final classes: {dataset.classes}\")\n",
        "    torch.save(model.state_dict(), 'card_classifier.pth')"
      ],
      "metadata": {
        "id": "3nxlf2peFMkU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Supervised Fine-tuning\n",
        "\n",
        "This block calls the `finetune_supervised_model` function to start the supervised fine-tuning process."
      ],
      "metadata": {
        "id": "XOhqbvwEcwp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the supervised fine-tuning if this script is executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    finetune_supervised_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1448kyWFN-J",
        "outputId": "074dde43-89c7-4fc3-d382-833e87182ac3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Supervised Finetuning on 20 labeled images ---\n",
            "Epoch 1, Loss: 2.9179\n",
            "Epoch 2, Loss: 0.8795\n",
            "Epoch 3, Loss: 0.6428\n",
            "Epoch 4, Loss: 0.4396\n",
            "Epoch 5, Loss: 0.7948\n",
            "Epoch 6, Loss: 0.6388\n",
            "Epoch 7, Loss: 0.4400\n",
            "Epoch 8, Loss: 0.3779\n",
            "Epoch 9, Loss: 0.4198\n",
            "Epoch 10, Loss: 0.4384\n",
            "Epoch 11, Loss: 0.4952\n",
            "Epoch 12, Loss: 0.4096\n",
            "Epoch 13, Loss: 0.4351\n",
            "Epoch 14, Loss: 0.4381\n",
            "Epoch 15, Loss: 0.4322\n",
            "Epoch 16, Loss: 0.6738\n",
            "Epoch 17, Loss: 0.4227\n",
            "Epoch 18, Loss: 0.5362\n",
            "Epoch 19, Loss: 0.3780\n",
            "Epoch 20, Loss: 0.3867\n",
            "\n",
            "Finetuning finished! The model is now ready for card classification.\n",
            "Final classes: ['bank_card', 'id_card', 'visiting_card', 'voter_id']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Classifier Model (for Prediction)\n",
        "\n",
        "This is the same `FullClassifier` model definition used for fine-tuning, included again for clarity in the prediction section. It loads the pre-trained encoder and the fine-tuned classifier head."
      ],
      "metadata": {
        "id": "rlsX1k6-FRzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullClassifier(nn.Module):\n",
        "    def __init__(self, encoder_path, num_classes):\n",
        "        super(FullClassifier, self).__init__()\n",
        "        # Define encoder structure (must match pre-trained encoder)\n",
        "        class SimpleCNN_Encoder(nn.Module):\n",
        "            def __init__(self):\n",
        "                super(SimpleCNN_Encoder, self).__init__()\n",
        "                self.encoder = nn.Sequential(\n",
        "                    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2, 2),\n",
        "                    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2, 2)\n",
        "                )\n",
        "            def forward(self, x):\n",
        "                return self.encoder(x)\n",
        "        self.encoder = SimpleCNN_Encoder().encoder\n",
        "        # Note: state_dict for encoder is loaded with the full model's state_dict\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 32 * 32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        output = self.classifier(features)\n",
        "        return output"
      ],
      "metadata": {
        "id": "16E6mcu8FPlj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Image Function\n",
        "\n",
        "This function takes a trained model, an image path, and a list of class names, and predicts the class of the given image. It applies the necessary transformations and uses the model to get the predicted class label."
      ],
      "metadata": {
        "id": "Y-hppMgpc8OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(model, image_path, classes):\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Error: Image file not found at '{image_path}'\")\n",
        "        return None\n",
        "    # Apply same transforms as during training\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        predicted_idx = torch.argmax(output).item()\n",
        "    predicted_class = classes[predicted_idx]\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "wIPo-g9WFUFX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a Prediction\n",
        "\n",
        "This block loads the trained model and uses the `predict_image` function to make a prediction on a new image."
      ],
      "metadata": {
        "id": "EoI3HZq1c_RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set model and image paths\n",
        "    model_path = 'card_classifier.pth'\n",
        "    new_image_path = '/content/drive/MyDrive/cards_labeled_small/b_0118.png'  # Path for Colab uploads\n",
        "    # List of class names in training order\n",
        "    final_classes = ['bank_card', 'id_card', 'visiting_card', 'voter_id']\n",
        "    num_classes = len(final_classes)\n",
        "    # Load trained model\n",
        "    model = FullClassifier(encoder_path='self_supervised_encoder.pth', num_classes=num_classes)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        print(\"Final model loaded successfully!\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Model file '{model_path}' not found. Please check the path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the model: {e}\")\n",
        "    print(f\"\\nMaking a prediction for the image at: {new_image_path}\")\n",
        "    predicted_label = predict_image(model, new_image_path, final_classes)\n",
        "    if predicted_label:\n",
        "        print(f\"\\nThe model predicts this card is a: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y4yVAFyFVl5",
        "outputId": "0117f9ab-4c6c-4740-c7d0-588d79e600db"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model loaded successfully!\n",
            "\n",
            "Making a prediction for the image at: /content/drive/MyDrive/cards_labeled_small/b_0118.png\n",
            "\n",
            "The model predicts this card is a: bank_card\n"
          ]
        }
      ]
    }
  ]
}